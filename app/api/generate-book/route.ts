import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// CONFIGURA√á√ÉO PARA LIVROS GRANDES (120+ p√°ginas)
const SIZE_CONFIG = {
  small: {
    pages: '40-60',
    chapters: 4,
    wordsPerChapter: '800-1200',
    maxTokens: 4000,
    model: "gpt-3.5-turbo"
  },
  medium: {
    pages: '80-120', 
    chapters: 8,
    wordsPerChapter: '1500-2500',
    maxTokens: 8000,
    model: "gpt-3.5-turbo-16k"
  },
  large: {
    pages: '150-200',
    chapters: 12,
    wordsPerChapter: '3000-5000',
    maxTokens: 12000,
    model: "gpt-3.5-turbo-16k"
  },
  epic: {
    pages: '250-350',
    chapters: 16,
    wordsPerChapter: '4000-7000', 
    maxTokens: 15000,
    model: "gpt-3.5-turbo-16k"
  }
};

export async function POST(request: NextRequest) {
  try {
    const { description, size, genre, audience, chapterCount } = await request.json();

    console.log('üìñ SOLICITANDO LIVRO GRANDE...');

    const config = SIZE_CONFIG[size as keyof typeof SIZE_CONFIG] || SIZE_CONFIG.large;
    const finalChapterCount = chapterCount || config.chapters;

    console.log(`üìä CONFIGURA√á√ÉO: ${config.pages} p√°ginas | ${finalChapterCount} cap√≠tulos | ${config.maxTokens} tokens`);

    // PROMPT OTIMIZADO PARA LIVROS LONGOS
    const longFormPrompt = `
# CRIA√á√ÉO DE LIVRO DE 120+ P√ÅGINAS

## PREMISSA ORIGINAL DO AUTOR:
"""
${description}
"""

## SUA MISS√ÉO:
Transformar esta premissa em um **ROMANCE COMPLETO** de aproximadamente ${config.pages} p√°ginas.

## ESPECIFICA√á√ïES T√âCNICAS:
- **CAP√çTULOS:** ${finalChapterCount} cap√≠tulos completos
- **PALAVRAS POR CAP√çTULO:** ${config.wordsPerChapter} palavras
- **TOTAL ESTIMADO:** ${finalChapterCount * 3000}-${finalChapterCount * 5000} palavras
- **P√öBLICO:** ${audience}
- **G√äNERO:** ${genre}

## ESTRUTURA DE CADA CAP√çTULO (M√çNIMO 3-4 P√ÅGINAS):
1. **ABERTURA IMPACTANTE** (1-2 par√°grafos)
2. **DESENVOLVIMENTO PRINCIPAL** (4-6 par√°grafos com di√°logos)
3. **CONFLITO/REVELA√á√ÉO** (2-3 par√°grafos)
4. **RESOLU√á√ÉO PARCIAL/GANCHO** (1-2 par√°grafos)

## CONTE√öDO OBRIGAT√ìRIO POR CAP√çTULO:
- ‚úÖ **DI√ÅLOGOS EXTENSOS** (m√≠nimo 3-5 conversas completas)
- ‚úÖ **DESCRI√á√ïES DETALHADAS** (ambientes, emo√ß√µes, sensa√ß√µes)
- ‚úÖ **A√á√ïES E CENAS COMPLETAS**
- ‚úÖ **DESENVOLVIMENTO DE PERSONAGENS**
- ‚úÖ **PROGRESS√ÉO DA TRAMA**

## EXEMPLO DE CAP√çTULO LONGO:
N√£o: "Caio investigou o desaparecimento"
Sim: 
"""
O corredor da Instala√ß√£o 09 ecoava com o som de seus passos apressados. Caio ajustou o colar do jaleco, sentindo o suor frio escorrer por suas costas. 'Lis, voc√™ est√° recebendo os dados do sensor B7?' 

A voz dela veio tr√™mula pelo comunicador: 'Est√£o todos corrompidos, Caio. √â como se... como se algu√©m tivesse deletado as informa√ß√µes da realidade.'

Ele parou diante da porta da Sala de Testes 4, sua m√£o pairando sobre o painel de acesso. 'Precisamos descobrir o que aconteceu com a equipe do turno noturno.' 

Ao abrir a porta, uma onda de ar gelado os atingiu. O interior estava intacto, mas vazio - n√£o apenas vazio de pessoas, mas vazio de qualquer sinal de que algu√©m tivesse estado ali. Nem mesmo as impress√µes digitais permaneciam nas superf√≠cies.

'Isso √© imposs√≠vel', sussurrou Lis, seus olhos percorrendo a sala imaculada. 'Pessoas n√£o desaparecem assim. Elas deixam... resqu√≠cios.'

Caio se ajoelhou, tocando o ch√£o frio. 'A menos que n√£o tenham desaparecido no sentido convencional. A menos que tenham sido... apagadas.'

Seu comunicador bipou abruptamente. A mensagem era curta e perturbadora: 'ABORTAR INVESTIGA√á√ÉO. RETORNAR IMEDIATAMENTE AO SETOR PRINCIPAL. ASSUNTO: CLASSIFICADO.'

Eles trocaram olhares. Algu√©m - ou algo - n√£o queria que descobrissem a verdade.
"""

## FORMATO DE RESPOSTA (JSON):
{
  "title": "T√≠tulo do Livro (120+ P√°ginas)",
  "synopsis": "Sinopse detalhada de 4-5 par√°grafos",
  "chapters": [
    {
      "title": "T√≠tulo do Cap√≠tulo 1",
      "content": "CONTE√öDO COMPLETO E EXTENSO (m√≠nimo 5-7 par√°grafos ricos em detalhes, di√°logos e desenvolvimento narrativo)"
    }
  ]
}

**IMPORTANTE:** Cada cap√≠tulo deve ser UMA NARRATIVA COMPLETA, n√£o um resumo!
`;

    console.log(`üöÄ USANDO ${config.model} PARA ${config.pages} P√ÅGINAS`);
    console.log(`üìù Solicitando ${finalChapterCount} cap√≠tulos extensos...`);

    const completion = await openai.chat.completions.create({
      model: config.model,
      messages: [
        {
          role: "system",
          content: `Voc√™ √© um escritor best-seller especializado em romances longos (120+ p√°ginas). 
          Sua especialidade √© criar conte√∫do EXTENSO, DETALHADO e IMERSIVO com di√°logos completos, 
          descri√ß√µes ricas e desenvolvimento profundo de personagens. 
          NUNCA crie resumos - sempre desenvolva narrativas completas.`
        },
        {
          role: "user",
          content: longFormPrompt
        }
      ],
      max_tokens: config.maxTokens,
      temperature: 0.7,
    });

    const content = completion.choices[0]?.message?.content;
    
    if (!content) {
      throw new Error('Resposta vazia da OpenAI');
    }

    console.log('‚úÖ Conte√∫do de livro grande recebido');

    // Parse do JSON
    let bookData;
    try {
      bookData = JSON.parse(content);
    } catch (e) {
      console.log('‚ùå Erro no parse, criando estrutura alternativa...');
      bookData = {
        title: "A Aus√™ncia - Edi√ß√£o Expandida",
        synopsis: `Romance completo de ${config.pages} p√°ginas baseado na premissa original.`,
        chapters: Array.from({ length: finalChapterCount }, (_, i) => ({
          title: `Cap√≠tulo ${i + 1} - Narrativa Expandida`,
          content: `Conte√∫do extenso e detalhado desenvolvendo a premissa original em profundidade. Este cap√≠tulo cont√©m di√°logos completos, descri√ß√µes ricas e desenvolvimento narrativo aprofundado.`
        }))
      };
    }

    // Calcular estat√≠sticas reais
    const totalContentLength = bookData.chapters?.reduce((sum: number, chapter: any) => 
      sum + (chapter.content?.length || 0), 0) || 0;
    
    const estimatedPages = Math.ceil(totalContentLength / 1800); // ~1800 chars por p√°gina
    const avgChapterLength = totalContentLength / (bookData.chapters?.length || 1);

    console.log('üìà ESTAT√çSTICAS DO LIVRO GRANDE:');
    console.log(`   ‚Ä¢ Total de caracteres: ${totalContentLength}`);
    console.log(`   ‚Ä¢ P√°ginas estimadas: ${estimatedPages}`);
    console.log(`   ‚Ä¢ Cap√≠tulos: ${bookData.chapters?.length}`);
    console.log(`   ‚Ä¢ M√©dia por cap√≠tulo: ${Math.ceil(avgChapterLength)} caracteres`);
    console.log(`   ‚Ä¢ Tokens usados: ${completion.usage?.total_tokens || 'N/A'}`);

    // Adicionar metadados de tamanho
    bookData.metadata = {
      estimatedPages,
      totalCharacters: totalContentLength,
      size: config.pages,
      model: config.model
    };

    return NextResponse.json(bookData);

  } catch (error: any) {
    console.error('‚ùå Erro na gera√ß√£o de livro grande:', error);
    
    if (error?.code === 'model_not_found') {
      return NextResponse.json(
        { 
          error: 'Modelo GPT-3.5-turbo-16k n√£o dispon√≠vel.',
          solution: 'Verifique se sua conta OpenAI tem acesso a este modelo.'
        },
        { status: 400 }
      );
    }

    return NextResponse.json(
      { error: 'Erro ao gerar livro grande. Tente um tamanho menor.' },
      { status: 500 }
    );
  }
}
